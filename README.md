<p align="center">
    <br>
    <img src="https://superarlue.dlnlp.ai/assets/superARLUE_logo.png" width="50%"/>
    <br>
<p>

<p align="center">
<a href="https://github.com/UBC-NLP/superarlue/releases">
        <img alt="GitHub release" src="https://img.shields.io/github/release/UBC-NLP/superarlue.svg">
    </a>

<a href="https://superarlue.dlnlp.ai/">
        <img alt="Documentation" src="https://img.shields.io/website.svg?down_color=red&down_message=offline&up_message=online&url=https://superarlue.dlnlp.ai">
    </a>
<a href="https://github.com/UBC-NLP/superarlue/blob/main/LICENSE"><img alt="GitHub license" src="https://img.shields.io/github/license/UBC-NLP/superarlue?logoColor=blue"></a>
<a href='https://superarlue.readthedocs.io/en/latest/?badge=latest'><img src='https://readthedocs.org/projects/superarlue/badge/?version=latest' alt='Documentation Status' /></a>
<a href="https://github.com/UBC-NLP/superarlue/stargazers"><img alt="GitHub stars" src="https://img.shields.io/github/stars/UBC-NLP/superarlue"></a>
<a href="https://github.com/UBC-NLP/superarlue/network"><img alt="GitHub forks" src="https://img.shields.io/github/forks/UBC-NLP/superarlue"></a>

</p>
 
<p>Over the last few years, several pre-trained languages models and transfer learning techniques have been proposed and led to a significant performance improvement across diverse natural language understanding (NLU) tasks. Although several NLU benchmarks models have been introduced in order to evaluate the effectiveness of such pre-trained models and techniques. <br>
<b>SuperARLUE</b> is a large-scale ARabic Language Understanding and Evaluation benchmark styled after ARLUE (AbdulMageed et al., 2021) with a new set of publicly available NLU tasks and datasets. It's composed of 60 publicly available datasets and covers seven NLU task clusters. Moreover, we provide a deep comprehensive comparison of the performance of all recently released Arabic pre-trained language models on <b>SuperARLUE</b>  benchmark. </p>
  
# superarlue